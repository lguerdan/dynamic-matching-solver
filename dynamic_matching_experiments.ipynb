{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from gurobi import *\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "pd.options.display.max_columns = None\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import display_html\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_palette(sns.color_palette(\"colorblind\", 10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "from dynamic_matching_solvers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First create some visualization functions for better understanding how the solvers are performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_3D(tableaus_int, tableaus_float, names, c, k, T, alphas):\n",
    "    '''Given an array of numpy arrays, transforms to dataframes and displays'''\n",
    "    \n",
    "    metadf = pd.DataFrame({\n",
    "        'copies' :[c[i] for i in range(allocs.shape[0])],\n",
    "        'use times' :[k[i] for i in range(allocs.shape[0])]\n",
    "    })\n",
    "    \n",
    "    html_str = ('<th>' \n",
    "                + ''.join([f'<td style=\"text-align:center\">{name}</td>' for name in names])\n",
    "                + '</th>')\n",
    "\n",
    "    int_ixs = len(tableaus_int)-1\n",
    "    tableaus_int.extend(tableaus_float)\n",
    "    \n",
    "    for i in range(T):\n",
    "        row_dfs = [pd.DataFrame(tableau[:,:,i]) for tableau in tableaus_int]\n",
    "    \n",
    "        html_str += ('<tr>' + \"<td style='vertical-align:center'> t = {}\".format(i) +\n",
    "                     f\"<td style='vertical-align:top'>{metadf.to_html(index=False, float_format='%i')}</td>\" +\n",
    "                     ''.join(f\"<td style='vertical-align:top'> {df.to_html(index=False, float_format=ix_to_format(ix,int_ixs))}</td>\"\n",
    "                             for ix,df in enumerate(row_dfs)) + \n",
    "                     '</tr>')\n",
    "        \n",
    "    \n",
    "    html_str = f'<table>{html_str}</table>'\n",
    "    \n",
    "    \n",
    "    columns=[\"t=\"+str(t) for t in range(T)]\n",
    "    index=[\"i=\"+str(i) for i in range(I)]\n",
    "    dfa = pd.DataFrame(alphas.reshape(I,T),columns=columns, index=index)\n",
    "\n",
    "    columns = [\"j=\"+str(j) for j in range(J)]\n",
    "    dfb = pd.DataFrame(betas.reshape(1,J),columns=columns)\n",
    "\n",
    "    html_str += f'<table><th><td style=\"text-align:center\">alpha[i,t]</td><td style=\"text-align:center\">beta[j]</td></th><tr><td></td><td>{dfa.to_html()}</td><td>{dfb.to_html()}</td></tr></table>' \n",
    "    \n",
    "    display_html(html_str, raw=True) \n",
    "\n",
    "    \n",
    "def ix_to_format(ix,intix):\n",
    "    if ix > intix:\n",
    "        return '%.3e'\n",
    "    elif ix > intix:\n",
    "        return '%.3f'\n",
    "    else:\n",
    "        return '%i'\n",
    "        \n",
    "def check_comp_terms(I,J,T,alphas, betas):\n",
    "    \n",
    "    comp_terms = np.zeros((I,J,T))\n",
    "    for t in range(T):\n",
    "        for j in range(J):\n",
    "            for i in range(I):\n",
    "                    comp_terms[i,j,t] = pairing_weights[i,j,t] - sum_alpha_it(alphas,i,t,k) - betas[j]                  \n",
    "    return comp_terms\n",
    "\n",
    "def check_comp_slackness(I,J,T,alphas,valid_matches, allocs):\n",
    "    \n",
    "    comp_slackness = np.zeros(valid_matches.shape)\n",
    "    \n",
    "    for t in range(T):\n",
    "        for j in range(J):\n",
    "            for i in range(I):\n",
    "                    comp_slackness[i,j,t] = (pairing_weights[i,j,t] - sum_alpha_it(alphas,i,t,k) - betas[j]) * allocs[i,j,t]\n",
    "                    \n",
    "    return comp_slackness\n",
    "\n",
    "def print_tableau(matches):\n",
    "    for i in range(matches.shape[2]):\n",
    "        print(\"t=\",i)\n",
    "        print(matches[:,:,i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments calling the solvers defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing greedy vs. online dual vs. optimal in a slightly larger simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simulation_scenario(I,J,T, scenario=None, arrivals=''):\n",
    "    \"Defines tableau for 2 x 2 model according to arrivals and agent scenario distribution\"\n",
    "    if scenario:\n",
    "        assert I == scenario['k'].size and I == scenario['c'].size and I == len(scenario['resource_configs'])+1, 'Scenario provided is not valid'\n",
    "        assert arrivals != '', 'Arrival model not specified'\n",
    "    \n",
    "    valid_matches = np.zeros((I,J,T), np.int)\n",
    "    weight_noise = np.random.random(valid_matches.shape) \n",
    "\n",
    "    #Only consider valid indicies\n",
    "    for t in range(T):\n",
    "        valid_matches[:,max(0,t-d):min(t+1,J),t] = 1\n",
    "\n",
    "    if scenario == None:\n",
    "        pairing_weights = np.random.random(valid_matches.shape) \n",
    "\n",
    "    #Construct matching matrix based on scenario configuration\n",
    "    else:\n",
    "        pairing_weights = np.zeros(valid_matches.shape)\n",
    "        \n",
    "        for resource_ix, config in enumerate(scenario['resource_configs']):\n",
    "            \n",
    "            if arrivals == \"Alternating\":\n",
    "                agentAs = np.arange(J)[::2]\n",
    "                agentBs = np.arange(J)[1::2]\n",
    "\n",
    "            elif arrivals == \"Stochastic\":\n",
    "                pA = scenario['resource_configs'][resource_ix]['probability-A']\n",
    "                agentAs = np.arange(J)[np.random.choice([1, 0], size=J, p=[pA, 1-pA]) == 1]\n",
    "                agentBs = np.setdiff1d(np.arange(J), agentAs)\n",
    "\n",
    "            elif arrivals == \"Adversarial\":\n",
    "                agentAs = np.arange(J)[0:int(J/2)]\n",
    "                agentBs = np.setdiff1d(np.arange(J), agentAs)\n",
    "                \n",
    "            pairing_weights[resource_ix+1,agentAs,:] = scenario['resource_configs'][resource_ix]['agent-A']\n",
    "            pairing_weights[resource_ix+1,agentBs,:] = scenario['resource_configs'][resource_ix]['agent-B']\n",
    "\n",
    "    #Random noise to break ties\n",
    "    for t in range(1,pairing_weights.shape[2]):\n",
    "        pairing_weights[:,:,t] = pairing_weights[:,:,0] + .0001 * weight_noise[:,:,t]  \n",
    "    \n",
    "    #Modify pairing weights based on problem formulation \n",
    "    pairing_weights[0,:,:] =  0\n",
    "    pairing_weights[valid_matches == 0] = -1\n",
    "    pairing_weights[1:,:,:] = np.round(pairing_weights[1:,:,:],decimals=8)\n",
    "\n",
    "    return valid_matches, pairing_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing performance of online-dual, greedy, offline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_smr(I,J,T,arrivals='',scenario=None,plot=True):\n",
    "    '''Run many simulations with different resource copy and use time properties. Plot performance as a function of resource scarcity'''\n",
    "    primal_objs = []\n",
    "    online_objs = []\n",
    "    greedy_objs = []\n",
    "    smrs = []\n",
    "\n",
    "    for cmax in range(2,10):\n",
    "        for kmin in range(4,12):\n",
    "            for kmax in range(14,22):\n",
    "                \n",
    "                for p in range(12):\n",
    "\n",
    "                    valid_matches, pairing_weights = create_simulation_scenario(I, J, T, scenario, arrivals)\n",
    "\n",
    "                    k = np.insert(np.random.randint(kmin,kmax,size=I-1), 0, 1)\n",
    "                    c = np.insert(np.random.randint(1,cmax,size=I-1), 0, J)\n",
    "\n",
    "                    objp, allocs = primal_solutions(valid_matches, pairing_weights, I, J, T, k, c)\n",
    "                    objd, alphas, betas = dual_solutions(valid_matches,pairing_weights, I, J, T, k, c)\n",
    "                    objo, online_allocations = online_matching(I,J,T,k,c,alphas,betas,allocs,valid_matches,pairing_weights)\n",
    "                    objg, greedy_allocs = greedy_matching(I,J,T,k,c,d,valid_matches,pairing_weights)\n",
    "\n",
    "                    smr = np.round((J - allocs.sum()) / J, 3)\n",
    "\n",
    "                    primal_objs.append(objp)\n",
    "                    online_objs.append(objo)\n",
    "                    greedy_objs.append(objg)\n",
    "                    smrs.append(smr)\n",
    "\n",
    "    if plot: \n",
    "        make_smr_plot(smrs, primal_objs, online_objs, greedy_objs)  \n",
    "    \n",
    "    return smrs, primal_objs, online_objs, greedy_objs\n",
    "\n",
    "def make_smr_plot(smrs, primal_objs, online_objs, greedy_objs):\n",
    "    '''Creates resource scarcity line plot'''\n",
    "    smrt = 100 - (np.array(smrs) * 100)\n",
    "    rundf = pd.DataFrame({'smrs': smrt, 'Offline Primal (Optimal)': primal_objs, 'Online Greedy': greedy_objs, 'Online Dual' : online_objs})\n",
    "    plt.figure(figsize=(10,7))\n",
    "    ax = sns.lineplot(x=\"smrs\", y=\"value\", data=pd.melt(rundf, ['smrs']), hue='variable')\n",
    "    ax.set(xlabel='Percent of agents matched in optimal', ylabel='Match utility', title=f'Performance as a function of resource scarcity')\n",
    "\n",
    "    legend = ax.legend()\n",
    "    legend.texts[0].set_text(\"Algorithm\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def compare_single_config(I, J, T, k, c, arrivals, scenario=None, plot=True, n_samples=40):\n",
    "    '''For a single k,c configuration, run multiple simulations to compare performance distributions, optionally plotting the result'''\n",
    "    primal_objs = []\n",
    "    online_objs = []\n",
    "    greedy_objs = []\n",
    "    smrs = []\n",
    "\n",
    "    for i in range(n_samples):\n",
    "\n",
    "        valid_matches, pairing_weights = create_simulation_scenario(I, J, T, scenario, arrivals)\n",
    "\n",
    "        objp, allocs = primal_solutions(valid_matches, pairing_weights, I, J, T, k, c)\n",
    "        objd, alphas, betas = dual_solutions(valid_matches,pairing_weights, I, J, T, k, c)\n",
    "        objo, online_allocations = online_matching(I,J,T,k,c,alphas,betas,allocs,valid_matches,pairing_weights)\n",
    "        objg, greedy_allocs = greedy_matching(I,J,T,k,c,d,valid_matches,pairing_weights)\n",
    "\n",
    "        smr = np.round((J - allocs.sum()) / J, 3)\n",
    "\n",
    "        primal_objs.append(objp)\n",
    "        online_objs.append(objo)\n",
    "        greedy_objs.append(objg)\n",
    "        smrs.append(smr)\n",
    "    \n",
    "    if plot:\n",
    "        rundf= pd.DataFrame({'Primal': primal_objs, 'Online' : online_objs, 'Greedy': greedy_objs})\n",
    "        plt.figure(figsize=(10,7))\n",
    "        ax = sns.catplot(x=\"variable\", y=\"value\",  data=pd.melt(rundf))\n",
    "\n",
    "        ax.set(xlabel='Matching algorithm', ylabel='Mean match utility', title=f'Average utility across 40 runs ({np.array(smrs).mean()} avg self match ratio, {J} agents, {I} resources, {d} round wait time)')\n",
    "        plt.show()\n",
    "\n",
    "    return smrs, primal_objs, online_objs, greedy_objs\n",
    "\n",
    "def make_noise_plot(k,c,arrivals,scenariokey,scenario=None,):\n",
    "\n",
    "    primal_objs = []\n",
    "    online_objs = []\n",
    "    greedy_objs = []\n",
    "    smrs = []\n",
    "    objos = []\n",
    "    noises = []\n",
    "    noise_terms = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 5e-1]\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        valid_matches, pairing_weights = create_simulation_scenario(I,J,T, scenario, arrivals)\n",
    "\n",
    "        objp, allocs = primal_solutions(valid_matches, pairing_weights, I, J, T, k, c)\n",
    "        objd, alphas, betas = dual_solutions(valid_matches,pairing_weights, I, J, T, k, c)\n",
    "        objo, online_allocations = online_matching(I,J,T,k,c,alphas,betas,allocs,valid_matches,pairing_weights)\n",
    "        objg, greedy_allocs = greedy_matching(I,J,T,k,c,d,valid_matches,pairing_weights)\n",
    "\n",
    "        smr = np.round((J - allocs.sum()) / J, 3)\n",
    "\n",
    "        primal_objs.append(objp)\n",
    "        online_objs.append(objo)\n",
    "        greedy_objs.append(objg)\n",
    "        smrs.append(smr)\n",
    "\n",
    "        for noise in noise_terms:\n",
    "            for i in range(40):\n",
    "\n",
    "                alphas_copy = alphas + noise * np.random.random(alphas.shape)\n",
    "                objo, online_allocations = online_matching(I,J,T,k,c,alphas_copy,betas,allocs,valid_matches,pairing_weights)\n",
    "                objos.append(objo)\n",
    "                noises.append(noise)\n",
    "                \n",
    "    rundf= pd.DataFrame({'Primal': primal_objs, 'Greedy': greedy_objs, 'Online Optimal Dual' : online_objs})\n",
    "    noisedf = pd.DataFrame({'noise_multiplier': noises, 'utility': objos})\n",
    "\n",
    "    plt.figure(figsize=(10,7))\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True,gridspec_kw={'width_ratios': [1, 2]})\n",
    "    fig.suptitle(f\"Scenario {scenariokey} & {arrivals} Arrival Model\".format(scenario,arrivals), fontsize=24)\n",
    "    fig.set_figwidth(12)\n",
    "\n",
    "\n",
    "    sns.catplot(x=\"variable\", y=\"value\",  data=pd.melt(rundf), kind='strip',ax=ax1,s=10)\n",
    "    ax1.set(xlabel='', ylabel='Match utility', title='Baseline')\n",
    "    plt.close() \n",
    "\n",
    "    sns.catplot(x=\"noise_multiplier\", y=\"utility\",  data=noisedf,  kind=\"strip\",s=10,ax=ax2)    \n",
    "    ax2.set(xlabel='Noise (%)', ylabel='', title='Online Dual with Increasing Noise')\n",
    "\n",
    "    fig.autofmt_xdate(rotation=45)\n",
    "    plt.tight_layout() \n",
    "\n",
    "    fig.subplots_adjust(top=0.75)\n",
    "    plt.close() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a simple scenario, run \n",
    "\n",
    "J=6\n",
    "I=3\n",
    "d=2\n",
    "T = J+d \n",
    "valid_matches, pairing_weights = create_simulation_scenario(I,J,T)\n",
    "\n",
    "k = np.array([1,3,3])\n",
    "c = np.array([J,1, 1])\n",
    "\n",
    "#To run the solvers, run: \n",
    "objp, allocs = primal_solutions(valid_matches, pairing_weights, I, J, T, k, c)\n",
    "objd, alphas, betas = dual_solutions(valid_matches,pairing_weights, I, J, T, k, c)\n",
    "objo, online_allocations = online_matching(I,J,T,k,c,alphas,betas,allocs,valid_matches,pairing_weights)\n",
    "objg, greedy_allocs = greedy_matching(I,J,T,k,c,d,valid_matches,pairing_weights)\n",
    "\n",
    "#You can then compare the allocations different algorithms make by, \n",
    "# display_3D([allocs, online_], tableaus_float, names, c, k, T, alphas)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 1: General comparison of online-dual, greedy, and primal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J=4\n",
    "I=3\n",
    "d=2\n",
    "T = J+d \n",
    "\n",
    "#Comparison across self-match-ratios\n",
    "smrs, po2, oo2, go2 = compare_smr(I,J,T)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundf= pd.DataFrame({'Offline Primal': po2,'Online Greedy': go2, 'Online Dual' : oo2})\n",
    "plt.figure(figsize=(15,8))\n",
    "ax = sns.catplot(x=\"variable\", y=\"value\",  data=pd.melt(rundf), kind='box')\n",
    "ax.set(xlabel='Matching algorithm', ylabel='Match utility', title=f'Overall Matching Algorithm Performance')\n",
    "ax.set_xticklabels(rotation=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp 2: Deterioration of online-assignment with increasing noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define specific scenarios where a greedy approach will perform sub-optimally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J=50\n",
    "I=3\n",
    "d=4\n",
    "T = J+d \n",
    "\n",
    "scenarios = {}\n",
    "scenarios['1'] = {}\n",
    "scenarios['1']['k'] = np.array([1,5,15])\n",
    "scenarios['1']['c'] =  np.array([J,10, 5])\n",
    "scenarios['1']['resource_configs'] = []\n",
    "scenarios['1']['resource_configs'].append({'agent-A': .05,'agent-B':.05,'probability-A': 1})\n",
    "scenarios['1']['resource_configs'].append({'agent-A': .1,'agent-B':.9,'probability-A': .5})\n",
    "\n",
    "\n",
    "scenarios['2'] = {}\n",
    "scenarios['2']['k'] =  np.array([1,5,5])\n",
    "scenarios['2']['c'] =  np.array([J,3, 3]) \n",
    "scenarios['2']['resource_configs'] = []\n",
    "scenarios['2']['resource_configs'].append({'agent-A': .99,'agent-B':.99,'probability-A': 1})\n",
    "scenarios['2']['resource_configs'].append({'agent-A': .95,'agent-B':.05,'probability-A': .5})\n",
    "\n",
    "\n",
    "scenarios['3'] = {}\n",
    "scenarios['3']['k'] = np.array([1,T,T])\n",
    "scenarios['3']['c'] = np.array([J,2,2])\n",
    "scenarios['3']['resource_configs'] = []\n",
    "scenarios['3']['resource_configs'].append({'agent-A': .05,'agent-B':.05,'probability-A': 1})\n",
    "scenarios['3']['resource_configs'].append({'agent-A': .1,'agent-B':.9,'probability-A': .5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a single scenario many times to get distribution comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single config comparison\n",
    "x,y,z = compare_single_config(I,J,T, k, c, arrivals='Stochastic', scenario=scenarios['1'], plot=True, n_samples=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make plot of performance deteriorating with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, scenario in scenarios.items():\n",
    "    for arrival in ['Alternating', 'Stochastic', 'Adversarial']:\n",
    "        make_noise_plot(scenario['k'], scenario['c'], arrival, key, scenario)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the allocation scenario \n",
    "\n",
    "### Including the number of resource copies pending, alpha duals, match weights, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resource_uses_from_alloc(I,J,T,c,k,allocs):\n",
    "\n",
    "    resources_used = np.zeros((I,T),dtype=np.float)\n",
    "    resources_available = np.repeat(np.expand_dims(c,axis=1),T,axis=1)\n",
    "\n",
    "    for t in range(T):\n",
    "        for i in range(I):\n",
    "            resources_used[i,t+1:t+k[i]-1] += allocs[i,:,t].sum()\n",
    "            resources_available[i,t+1:t+k[i]] -= int(allocs[i,:,t].sum())\n",
    "            \n",
    "    return resources_used, resources_available\n",
    "\n",
    "def plot_alloc_heatmap(weights, allocs, alphas, resources_available, resources_used):\n",
    "    fig, (ax0, ax1, ax2,ax4) = plt.subplots(nrows=4, figsize=(18,10))\n",
    "\n",
    "    ax0.set_title(\"Match value\", fontsize=16, fontweight=\"bold\")\n",
    "    ax1.set_title(\"Alpha duals\", fontsize=16, fontweight=\"bold\")\n",
    "    ax2.set_title(\"Number of resource copies available\", fontsize=16, fontweight=\"bold\")\n",
    "    ax4.set_title(\"Primal Allocations\", fontsize=16, fontweight=\"bold\")\n",
    "    \n",
    "    \n",
    "    sns.heatmap(weights[1:,:], cmap=\"BuPu\", linewidths=.5,ax=ax0)\n",
    "    sns.heatmap(alphas[1:,:], cmap=\"BuPu\", linewidths=.5,ax=ax1)\n",
    "    sns.heatmap(resources_available[1:,:], cmap=\"YlGnBu\", linewidths=.5, ax=ax2)\n",
    "    sns.heatmap(allocs[1:,:], cmap=\"BuPu\", linewidths=.5,ax=ax4)\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.6)\n",
    "    plt.show()\n",
    "\n",
    "def simulate_average_resource_uses(I,J,T,d,arrival='', scenario=None, n_runs=1):\n",
    "    \n",
    "    allocs_runs = np.zeros((n_runs,I,J,T))\n",
    "    weights_runs = np.zeros((n_runs,I,J,T))\n",
    "    alphas_runs = np.zeros((n_runs,I,T))\n",
    "    resources_available_runs = np.zeros((n_runs,I,T))\n",
    "    resources_used_runs = np.zeros((n_runs,I,T))\n",
    "    \n",
    "    k = scenario['k']\n",
    "    c = scenario['c']\n",
    "    \n",
    "    for run in range(n_runs):\n",
    "        \n",
    "        valid_matches, pairing_weights = create_simulation_scenario(I,J,T,scenario,arrival)\n",
    "\n",
    "        objp, allocs = primal_solutions(valid_matches, pairing_weights, I, J, T, k, c)\n",
    "        objd, alphas, betas = dual_solutions(valid_matches,pairing_weights, I, J, T, k, c)\n",
    "        objo, online_allocations = online_matching(I,J,T,k,c,alphas,betas,allocs,valid_matches,pairing_weights)\n",
    "        objg, greedy_allocs = greedy_matching(I,J,T,k,c,d,valid_matches,pairing_weights)\n",
    "\n",
    "        resources_used, resources_available = get_resource_uses_from_alloc(I,J,T,c,k,allocs)\n",
    "        \n",
    "        allocs_runs[run,:,:,:] = allocs\n",
    "        weights_runs[run,:,:,:] = pairing_weights\n",
    "        alphas_runs[run,:,:]= alphas.reshape(I,T)\n",
    "        resources_used_runs[run,:,:] = resources_used\n",
    "        resources_available_runs[run,:,:] = resources_available\n",
    "\n",
    "    weights_runs[weights_runs < 0] = 0\n",
    "    \n",
    "    return weights_runs.mean(axis=0).mean(axis=1), allocs_runs.mean(axis=0).mean(axis=1), alphas_runs.mean(axis=0), resources_used_runs.mean(axis=0), resources_available_runs.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the relationship between resource availability and alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30 agents of type A&B arrive in stochastic order. Below is matching for one randomly generated scenario. Y axis is resources of type each type, and X axis is t. Match value and primal allocatoins are averaged over J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I=3\n",
    "J=30\n",
    "d=2\n",
    "T=J+d\n",
    "\n",
    "c = np.array([J,3,3])\n",
    "k = np.array([1,5,5])\n",
    "\n",
    "weights, allocs, alphas, resources_used, resources_available = simulate_average_resource_uses(I,J,T,d,arrival='Stochastic',scenario=scenarios['2'],n_runs=20)\n",
    "plot_alloc_heatmap(weights, allocs, alphas, resources_available, resources_used)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same plot but with an alternating arrival order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weights, allocs, alphas, resources_used, resources_available = simulate_average_resource_uses(I,J,T,d,arrival='Alternating',scenario=scenarios['2'],n_runs=1)\n",
    "plot_alloc_heatmap(weights, allocs, alphas, resources_available, resources_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the scenario and running 20 times, averaging across runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "weights, allocs, alphas, resources_used, resources_available = simulate_average_resource_uses(I,J,T,d,arrival='Stochastic',scenario=scenarios['2'],n_runs=20)\n",
    "plot_alloc_heatmap(weights, allocs, alphas, resources_available, resources_used)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the averaged alpha vector to make allocation decisions\n",
    "\n",
    "- The below code will use run a simulation N_SIMULATION times, create an averaged alpha vector from all of these simulations, then use that average vector to conduct online matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_dict = {'Baseline': 'Randomly generated', 'Stochastic':'Stochastic A&B', 'Alternating':'Alternating A&B','Adversarial':'Adversarial A&B', 'I6':'5 resources, alternating arrivals'}\n",
    "def mean_alpha_vector(I,J,T, N_SIMULATION, N_TEST, arrivals='',scenario=None):\n",
    "    alpha_runs = np.zeros((N_SIMULATION, I*T))\n",
    "    alloc_runs = np.zeros((N_SIMULATION, I,J,T))\n",
    "    \n",
    "    k = scenario['k']\n",
    "    c = scenario['c']\n",
    "    \n",
    "\n",
    "    #Simulate several runs to get an average alpha vector for the scenario\n",
    "    for i in range(N_SIMULATION):\n",
    "        valid_matches, pairing_weights = create_simulation_scenario(I, J, T, scenario, arrivals)\n",
    "\n",
    "        objp, allocs = primal_solutions(valid_matches, pairing_weights, I, J, T, k, c)\n",
    "        objd, alphas, betas = dual_solutions(valid_matches,pairing_weights, I, J, T, k, c)\n",
    "        objo, online_allocations = online_matching(I,J,T,k,c,alphas,betas,allocs,valid_matches,pairing_weights)\n",
    "        objg, greedy_allocs = greedy_matching(I,J,T,k,c,d,valid_matches,pairing_weights)\n",
    "\n",
    "        alpha_runs[i,:] = alphas\n",
    "        alloc_runs[i,:,:,:] = allocs\n",
    "\n",
    "    mean_alphas = alpha_runs.mean(axis=0)\n",
    "    mean_alloc = alloc_runs.mean(axis=0).mean(axis=1)\n",
    "    \n",
    "    return mean_alphas, mean_alloc\n",
    "\n",
    "\n",
    "def simulate_alphas(I,J,T,N_SIMULATION,N_TEST,a=['Stochastic','Alternating','Adversarial'], scenario=None):\n",
    "    \n",
    "    objps = []\n",
    "    objos = []\n",
    "    objgs = []\n",
    "    snrs = []\n",
    "    arvls = []\n",
    "    \n",
    "    for arrivals in a:\n",
    "        \n",
    "        k = scenario['k']\n",
    "        c = scenario['c']\n",
    "        mean_alphas, mean_alloc = mean_alpha_vector(I,J,T, N_SIMULATION, N_TEST, arrivals, scenario)\n",
    "       \n",
    "        #Use the average vector to make allocation decisons several times\n",
    "        for i in range(N_TEST):\n",
    "            valid_matches, pairing_weights = create_simulation_scenario(I, J, T, scenario, arrivals)\n",
    "            objp, allocs = primal_solutions(valid_matches, pairing_weights, I, J, T, k, c)\n",
    "            objd, alphas, betas = dual_solutions(valid_matches,pairing_weights, I, J, T, k, c)\n",
    "            objo, online_allocations = online_matching(I,J,T,k,c,mean_alphas,betas,allocs,valid_matches,pairing_weights)\n",
    "            objg, greedy_allocs = greedy_matching(I,J,T,k,c,d,valid_matches,pairing_weights)\n",
    "\n",
    "            objps.append(objp)\n",
    "            objos.append(objo)\n",
    "            objgs.append(objg)\n",
    "            snrs.append(((J - allocs.sum()) / allocs.sum()))\n",
    "            arvls.append(display_dict[arrivals])\n",
    "            \n",
    "            rundf = pd.DataFrame({'Offline Primal':objps, 'Online Avg Dual':objos, 'Online Greedy':objgs, 'snrs':snrs, 'arrivals':arvls})\n",
    "\n",
    "    return rundf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SIMULATION = 50\n",
    "N_TEST = 30\n",
    "\n",
    "d=2\n",
    "J=30\n",
    "I=3\n",
    "T = J+d \n",
    "\n",
    "simdf = simulate_alphas(I,J,T,N_SIMULATION,N_TEST,a=['Stochastic','Alternating','Adversarial'], scenario=scenarios['3'])\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "ax = sns.catplot(x=\"variable\", y=\"value\", col='arrivals',  data=pd.melt(simdf,id_vars=['snrs','arrivals']), kind='violin')\n",
    "ax.set_xticklabels(rotation=30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
